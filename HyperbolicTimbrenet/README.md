# TimbreNet

This project aims to create deep learning tools for musicians to work with the timbre of different sounds and instruments.

```bash

|__ğŸ“œtimbrenet_generate_chord.py
|
|__ğŸ“œtimbrenet_generate_latent_map.py
|
|__ğŸ“œtimbrenet_train.py
|
|
|__ğŸ“‚datasets/450pianoChordDataset
|   |__ğŸ“‚audio
|   |__ğŸ“œREADME.md
|
|__ğŸ“‚generated_chords
|
|__ğŸ“‚lib
|  |__ğŸ“œlatent_chord.py
|  |__ğŸ“œmodel.py
|  |__ğŸ“œspecgrams_helper.py
|  |__ğŸ“œspectral_ops.py
|  |__ğŸ“‚hyp_model           # hyperbolic layers
|  |   |__ğŸ“œ__init_.py
|  |   |__ğŸ“œlinear_hyp.py
|  |   |__ğŸ“œmanifold.py
|  |   |__ğŸ“œutil.py
|  |
|  |__ğŸ“‚models          # models
|  |   |__ğŸ“œ__init_.py
|  |   |__ğŸ“œbaseline.py
|  |   |__ğŸ“œbaseline_hyp.py
|  |   |__ğŸ“œbreguel_model.py
|  |   |__ğŸ“œhyp_vae.py
|  |   |__ğŸ“œmircea_model.py
|
|__ğŸ“‚logs/gradient_tape/2022_12_09 #cache for training model
|
|__ğŸ“‚results
|  |   |__ğŸ“œDowloand_file.ipynb    # dowloand the weights of the models
|  |   |__ğŸ“‚baseline
|  |   |__ğŸ“‚baseline_hyp
|  |   |__ğŸ“‚breguel_model
|  |   |__ğŸ“‚mircea_model   # * all the models have the same structure
|  |   |   |__ğŸ“‚model_weights
|  |   |   |__ğŸ“œloss.txt
|  |   |__ğŸ“‚analisis
|  |   |   |__ğŸ“‚sounds # audios of the generated chords of the top two models
|  |   |   |__ğŸ“œarchitectures.jpeg #  visual architecture of each model
|  |   |   |__ğŸ“œlosses.png # comparation of the losses of the models
|
|
|_ğŸ“‚trained_models/450_piano_chords    #pretrained models weights
```

- To run trained models you need to run the jupyter notebook Dowloand_file.ipynb, to dowloand the weight of each model from dropbox.

## Datasets

- PiancoChordDatastet: Dataset with 450 piano chords audios.

## Models

- TimbreNet_PianoChordVAE: VAE for encoding piano chords in a low-dimension latent space (2D - 3D). This latent space can be used to create new sounds of piano chords or create chord sequences by moving through the latent space.

## How to generate a chord from a trained model

- Clone this repository.
- Open timbrenet_generate_chord.py
- In the "trained_model_path" variable put the file with the weights of a trained model (there are some trained models in the "trained_models" folder.
- In the "latent_dim" variable select the latent dimention of the trained model.
- In the "sample_points" variable put all the poins from where you want to sample chords. You can samplle as many chords as you want at the same time. Each point needs to have the same ammount of dimentions as the "latent_dim" variable
- In the "chord_saving_path" put the path of the folder where you want to save the chords. If the folder does not exist, the code will create it for you.
- Finally, run timbrenet_generate_chord.py

## How to generate a 2D latent map

- Clone this repository.
- Open timbrenet_generate_latent_map.py
- In the "trained_model_path" variable put the file with the weights of a trained model (there are some trained models in the "trained_models" folder.
- In the "latent_dim" variable select the latent dimention of the trained model.
- In the "dataset_path" variable select the path of the dataset you want to plot.
- In the "instruments" select the instruments of the dataset you want to plot.
- In the "chords" select the chords of the dataset you want to plot.
- In the "volumes" select the volumes of the dataset you want to plot.
- In the "examples" select the examples of the dataset you want to plot.
- Finally, run timbrenet_generate_latent_map.py
